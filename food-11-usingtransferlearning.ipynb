{"cells":[{"cell_type":"markdown","metadata":{},"source":["**Implement Transfer learning with InceptionResNetV2-imagenet model**"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/kishore-yuva/nutrixy-phase-one/094b1b25dc27405e8d369076aa9297b7\n","\n"]}],"source":["from comet_ml import Experiment\n","from comet_ml.integration.pytorch import log_model\n","\n","experiment = Experiment(\n","  api_key=\"Your APi kEY\",\n","  project_name=\"Nutrixy_Phase_one\",\n","  workspace=\"kishore-yuva\",\n","  auto_histogram_weight_logging=True,\n","  auto_histogram_gradient_logging=True,\n","  auto_histogram_activation_logging=True,\n",")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:07:52.249077Z","iopub.status.busy":"2023-05-29T12:07:52.248524Z","iopub.status.idle":"2023-05-29T12:08:00.195364Z","shell.execute_reply":"2023-05-29T12:08:00.194369Z","shell.execute_reply.started":"2023-05-29T12:07:52.249045Z"},"trusted":true},"outputs":[],"source":["# Import libraries\n","import tensorflow as tf\n","from tensorflow.keras.applications import InceptionResNetV2\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:08:23.058672Z","iopub.status.busy":"2023-05-29T12:08:23.057957Z","iopub.status.idle":"2023-05-29T12:08:23.068443Z","shell.execute_reply":"2023-05-29T12:08:23.066732Z","shell.execute_reply.started":"2023-05-29T12:08:23.058633Z"},"trusted":true},"outputs":[],"source":["# Create an image data generator for image augmentation\n","datagen = ImageDataGenerator(\n","rescale=1./255,\n","rotation_range=20,\n","width_shift_range=0.2,\n","height_shift_range=0.2,\n","horizontal_flip=True,\n","fill_mode='nearest'\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:08:25.405328Z","iopub.status.busy":"2023-05-29T12:08:25.404858Z","iopub.status.idle":"2023-05-29T12:08:26.497376Z","shell.execute_reply":"2023-05-29T12:08:26.496426Z","shell.execute_reply.started":"2023-05-29T12:08:25.405289Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 9866 images belonging to 11 classes.\n","Found 3430 images belonging to 11 classes.\n","Found 3347 images belonging to 11 classes.\n"]}],"source":["# Create a training generator from the training folder\n","train_generator = datagen.flow_from_directory(\n","'dataset/training',\n","target_size=(224, 224),\n","batch_size=32,\n","class_mode='categorical',\n","shuffle=True\n",")\n","\n","# Create a validation generator from the validation folder\n","validation_generator = datagen.flow_from_directory(\n","'dataset/validation',\n","target_size=(224, 224),\n","batch_size=32,\n","class_mode='categorical',\n","shuffle=False\n",")\n","\n","# Create a evaluation generator from the evaluation folder\n","evaluation_generator = datagen.flow_from_directory(\n","'dataset/evaluation',\n","target_size=(224, 224),\n","batch_size=32,\n","class_mode='categorical',\n","shuffle=False\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# Custom callback to log metrics to Comet\n","class CometCallback(keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        experiment.log_metric(\"accuracy\", logs[\"accuracy\"], step=epoch)\n","        experiment.log_metric(\"loss\", logs[\"loss\"], step=epoch)\n","        experiment.log_metric(\"val_accuracy\", logs[\"val_accuracy\"], step=epoch)\n","        experiment.log_metric(\"val_loss\", logs[\"val_loss\"], step=epoch)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:08:17.322547Z","iopub.status.busy":"2023-05-29T12:08:17.322084Z","iopub.status.idle":"2023-05-29T12:08:17.380974Z","shell.execute_reply":"2023-05-29T12:08:17.380068Z","shell.execute_reply.started":"2023-05-29T12:08:17.322510Z"},"trusted":true},"outputs":[],"source":["\n","\n","# Load the pretrained model\n","base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","# Freeze the base model\n","base_model.trainable = False\n","# Add a global average pooling layer\n","x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n","# Add a dense layer with 11 units and softmax activation for classification\n","output = tf.keras.layers.Dense(11, activation='softmax')(x)\n","# Create the model\n","model = tf.keras.Model(inputs=base_model.input, outputs=output)\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:08:28.776243Z","iopub.status.busy":"2023-05-29T12:08:28.775856Z","iopub.status.idle":"2023-05-29T12:43:01.305675Z","shell.execute_reply":"2023-05-29T12:43:01.304718Z","shell.execute_reply.started":"2023-05-29T12:08:28.776201Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Sathish\\Desktop\\ImageClassification_project\\FI_cls_env\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m759s\u001b[0m 2s/step - accuracy: 0.6082 - loss: 1.2144 - val_accuracy: 0.7516 - val_loss: 0.7512\n","Epoch 2/20\n","\u001b[1m171/309\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4:15\u001b[0m 2s/step - accuracy: 0.7689 - loss: 0.6862"]},{"name":"stderr","output_type":"stream","text":["\u001b[1;38;5;196mCOMET ERROR:\u001b[0m Due to connectivity issues, there's an error in processing the heartbeat. The experiment's status updates might be inaccurate until the connection issues are resolved.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m793s\u001b[0m 3s/step - accuracy: 0.7706 - loss: 0.6795 - val_accuracy: 0.7641 - val_loss: 0.7048\n","Epoch 3/20\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m722s\u001b[0m 2s/step - accuracy: 0.8046 - loss: 0.5918 - val_accuracy: 0.7697 - val_loss: 0.7201\n","Epoch 4/20\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m717s\u001b[0m 2s/step - accuracy: 0.8141 - loss: 0.5617 - val_accuracy: 0.7942 - val_loss: 0.6307\n","Epoch 5/20\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m722s\u001b[0m 2s/step - accuracy: 0.8253 - loss: 0.5415 - val_accuracy: 0.8000 - val_loss: 0.6333\n","Epoch 6/20\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m714s\u001b[0m 2s/step - accuracy: 0.8196 - loss: 0.5371 - val_accuracy: 0.7869 - val_loss: 0.6393\n","Epoch 7/20\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m801s\u001b[0m 3s/step - accuracy: 0.8116 - loss: 0.5496 - val_accuracy: 0.8149 - val_loss: 0.5940\n","Epoch 8/20\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25023s\u001b[0m 81s/step - accuracy: 0.8327 - loss: 0.5026 - val_accuracy: 0.8140 - val_loss: 0.5840\n","Epoch 9/20\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m775s\u001b[0m 3s/step - accuracy: 0.8311 - loss: 0.4989 - val_accuracy: 0.8079 - val_loss: 0.5906\n","Epoch 10/20\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m800s\u001b[0m 3s/step - accuracy: 0.8304 - loss: 0.5019 - val_accuracy: 0.7880 - val_loss: 0.6368\n","Epoch 11/20\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m751s\u001b[0m 2s/step - accuracy: 0.8416 - loss: 0.4733 - val_accuracy: 0.8070 - val_loss: 0.6041\n","Epoch 12/20\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m793s\u001b[0m 3s/step - accuracy: 0.8435 - loss: 0.4701 - val_accuracy: 0.8076 - val_loss: 0.6239\n","Epoch 13/20\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m755s\u001b[0m 2s/step - accuracy: 0.8438 - loss: 0.4579 - val_accuracy: 0.8149 - val_loss: 0.5832\n","Epoch 14/20\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m752s\u001b[0m 2s/step - accuracy: 0.8494 - loss: 0.4379 - val_accuracy: 0.8108 - val_loss: 0.5965\n","Epoch 15/20\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m736s\u001b[0m 2s/step - accuracy: 0.8432 - loss: 0.4505 - val_accuracy: 0.8175 - val_loss: 0.5629\n","Epoch 16/20\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m778s\u001b[0m 3s/step - accuracy: 0.8431 - loss: 0.4661 - val_accuracy: 0.8155 - val_loss: 0.5658\n","Epoch 17/20\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m771s\u001b[0m 2s/step - accuracy: 0.8544 - loss: 0.4330 - val_accuracy: 0.8201 - val_loss: 0.5681\n","Epoch 18/20\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m793s\u001b[0m 3s/step - accuracy: 0.8513 - loss: 0.4463 - val_accuracy: 0.8102 - val_loss: 0.6257\n","Epoch 19/20\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m785s\u001b[0m 3s/step - accuracy: 0.8487 - loss: 0.4393 - val_accuracy: 0.8166 - val_loss: 0.5739\n","Epoch 20/20\n","\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m778s\u001b[0m 3s/step - accuracy: 0.8504 - loss: 0.4297 - val_accuracy: 0.8070 - val_loss: 0.6068\n"]}],"source":["\n","# Train the model for 10 epochs\n","history = model.fit(train_generator, epochs=20, validation_data=validation_generator,callbacks=[CometCallback()])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_loss, test_accuracy = model.evaluate(val_generator)\n","# Log test metrics\n","experiment.log_metric(\"test_loss\", test_loss)\n","experiment.log_metric(\"test_accuracy\",test_accuracy)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=tf\n"]}],"source":["model.save('models/ImagenetReset_1000.keras', save_format='tf')\n","experiment.log_model(\"keras_model\", \"models\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["experiment.end()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":4}
